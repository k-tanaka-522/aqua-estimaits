# 2.5.6.3 DBパフォーマンス測定

## 目的

データベースクエリのパフォーマンスを測定し、ボトルネックを特定します。

---

## 📊 DBパフォーマンス測定方法

### 1. スロークエリログ（PostgreSQL）

#### 設定

```sql
-- postgresql.conf
log_min_duration_statement = 100  -- 100ms以上のクエリをログ出力
log_line_prefix = '%t [%p]: user=%u,db=%d,app=%a,client=%h '
log_statement = 'all'  -- 開発環境のみ
```

#### ログ確認

```bash
# スロークエリログを確認
tail -f /var/log/postgresql/postgresql.log | grep "duration:"

# 出力例:
2025-10-19 10:15:30 JST [12345]: user=myapp,db=myapp_db duration: 523.142 ms  statement: SELECT * FROM users WHERE email LIKE '%@example.com';
```

---

### 2. EXPLAIN ANALYZE（実行計画分析）

```sql
-- ❌ 遅いクエリ例
EXPLAIN ANALYZE
SELECT * FROM orders
WHERE user_id = 123
  AND created_at > '2025-01-01';

-- 出力例:
Seq Scan on orders  (cost=0.00..15234.00 rows=1000 width=128) (actual time=0.042..125.342 rows=1000 loops=1)
  Filter: ((user_id = 123) AND (created_at > '2025-01-01'::date))
  Rows Removed by Filter: 999000
Planning Time: 0.234 ms
Execution Time: 125.678 ms
```

**問題**: Seq Scan（全表スキャン）

**改善策**: インデックス追加

```sql
-- ✅ インデックス追加
CREATE INDEX idx_orders_user_created ON orders(user_id, created_at);

-- 再度実行計画を確認
EXPLAIN ANALYZE
SELECT * FROM orders
WHERE user_id = 123
  AND created_at > '2025-01-01';

-- 改善後:
Index Scan using idx_orders_user_created on orders  (cost=0.42..12.45 rows=1000 width=128) (actual time=0.021..0.542 rows=1000 loops=1)
  Index Cond: ((user_id = 123) AND (created_at > '2025-01-01'::date))
Planning Time: 0.156 ms
Execution Time: 0.678 ms  -- 125ms → 0.678ms に改善！
```

---

### 3. pg_stat_statements（クエリ統計）

#### 有効化

```sql
-- postgresql.conf
shared_preload_libraries = 'pg_stat_statements'

-- 再起動後
CREATE EXTENSION pg_stat_statements;
```

#### 遅いクエリTOP10

```sql
SELECT
  query,
  calls,
  total_exec_time,
  mean_exec_time,
  max_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;
```

出力例:
```
                query                 | calls | total_exec_time | mean_exec_time | max_exec_time
--------------------------------------+-------+-----------------+----------------+---------------
SELECT * FROM orders WHERE user_id=? |  5000 |      125000.00  |         25.00  |       523.14
SELECT * FROM products WHERE ...     |  3000 |       90000.00  |         30.00  |       412.56
```

---

### 4. アプリケーションレベルでの測定

#### Python (SQLAlchemy)

```python
import time
from sqlalchemy import event
from sqlalchemy.engine import Engine
import logging

logger = logging.getLogger("sqlalchemy.engine")
logger.setLevel(logging.INFO)

@event.listens_for(Engine, "before_cursor_execute")
def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    conn.info.setdefault('query_start_time', []).append(time.time())

@event.listens_for(Engine, "after_cursor_execute")
def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    total = time.time() - conn.info['query_start_time'].pop(-1)
    if total > 0.1:  # 100ms以上
        logger.warning(f"Slow query ({total:.3f}s): {statement[:200]}")
```

#### TypeScript (TypeORM)

```typescript
import { Logger } from 'typeorm';

export class QueryLogger implements Logger {
  logQuery(query: string, parameters?: any[], queryRunner?: QueryRunner) {
    const start = Date.now();

    queryRunner?.on('query', () => {
      const duration = Date.now() - start;
      if (duration > 100) {  // 100ms以上
        console.warn(`Slow query (${duration}ms): ${query}`);
      }
    });
  }
}

// データソース設定
const dataSource = new DataSource({
  // ...
  logging: true,
  logger: new QueryLogger(),
});
```

---

### 5. N+1問題の検出

#### ❌ N+1問題の例

```python
# ❌ Bad: N+1クエリ
users = session.query(User).all()  # 1回のクエリ
for user in users:
    orders = user.orders  # N回のクエリ（ユーザー数だけ実行）
    print(f"{user.name}: {len(orders)} orders")

# 合計: 1 + N回のクエリ
```

#### ✅ 改善例（Eager Loading）

```python
# ✅ Good: Eager Loading
users = session.query(User).options(joinedload(User.orders)).all()  # 1回のクエリ（JOIN）
for user in users:
    orders = user.orders  # 追加クエリなし
    print(f"{user.name}: {len(orders)} orders")

# 合計: 1回のクエリ
```

#### TypeScript (TypeORM)

```typescript
// ❌ Bad: N+1
const users = await userRepository.find();
for (const user of users) {
  const orders = await orderRepository.find({ where: { userId: user.id } });
}

// ✅ Good: Eager Loading
const users = await userRepository.find({ relations: ['orders'] });
for (const user of users) {
  const orders = user.orders;  // 追加クエリなし
}
```

---

## 🎯 パフォーマンス目標

| 項目 | 目標値 |
|------|--------|
| 単純SELECT（主キー） | < 10ms |
| JOIN含むSELECT | < 50ms |
| 複雑な集計クエリ | < 200ms |
| INSERT/UPDATE | < 20ms |
| スロークエリ比率 | < 1% |

---

## 🔧 改善手法

### 1. インデックス追加

```sql
-- WHERE句でよく使うカラムにインデックス
CREATE INDEX idx_users_email ON users(email);

-- 複合インデックス（よく一緒に検索されるカラム）
CREATE INDEX idx_orders_user_status ON orders(user_id, status);
```

### 2. クエリの最適化

```sql
-- ❌ Bad: SELECT *
SELECT * FROM users WHERE email = 'test@example.com';

-- ✅ Good: 必要なカラムのみ
SELECT id, name, email FROM users WHERE email = 'test@example.com';
```

### 3. パーティショニング

```sql
-- 日付によるパーティショニング
CREATE TABLE orders_2025_01 PARTITION OF orders
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

### 4. 接続プールの最適化

```python
# SQLAlchemy
engine = create_engine(
    'postgresql://user:pass@localhost/db',
    pool_size=20,        # 接続プールサイズ
    max_overflow=10,     # プールを超えた場合の追加接続
    pool_pre_ping=True,  # 接続の健全性チェック
)
```

---

**作成日**: 2025-10-19
**重要度**: ⭐⭐⭐
